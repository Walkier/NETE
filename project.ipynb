{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start of the project\n",
    "#data preprocessing\n",
    "#convert data into csv format, also create train set, valid set and test set\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "from google.colab import drive\n",
    "from sklearn.model_selection import train_test_split\n",
    "drive.mount('/content/gdrive/')\n",
    "\n",
    "IMAGEPATH = 'gdrive/My Drive/Project1/dataset/images' #path linked to the file storing all images\n",
    "ANNOPATH = 'gdrive/My Drive/Project1/dataset/annotations' #path linked to the file storing all xml\n",
    "DATAPATH = 'gdrive/My Drive/Project1/dataset'\n",
    "\n",
    "features = {'image_name': [], 'width': [], 'height': [], 'xmin': [], 'ymin': [], 'xmax': [], 'ymax': [], 'label': []} #extracted information of each data\n",
    "\n",
    "for xml in os.listdir(ANNOPATH):\n",
    "  info = et.parse(ANNOPATH + '/' + xml)\n",
    "  root = info.getroot()\n",
    "  image = root[1].text\n",
    "  width = root[2][0].text\n",
    "  height = root[2][1].text\n",
    "  for i in range(4, len(root)):\n",
    "    label = root[i][0].text\n",
    "    #with_mask = 0, without_mask = 1, mask_weared_incorrect = 2\n",
    "    if label == 'with_mask':\n",
    "      label = 0\n",
    "    elif label == 'without_mask':\n",
    "      label = 1\n",
    "    elif label == 'mask_weared_incorrect':\n",
    "      label = 2\n",
    "    cur_data = []\n",
    "    cur_data.append(image)\n",
    "    cur_data.append(width)\n",
    "    cur_data.append(height)\n",
    "    for coord in root[i][5]:\n",
    "      cur_data.append(coord.text)\n",
    "    cur_data.append(label)\n",
    "    for i, feature in enumerate(features):\n",
    "      features[feature].append(cur_data[i])\n",
    "\n",
    "dataset = pd.DataFrame(features)\n",
    "target_count = dataset['label'].value_counts()\n",
    "print('Class 0: ', target_count[0])\n",
    "print('Class 1: ', target_count[1])\n",
    "print('Class 2: ', target_count[2])\n",
    "dataset.to_csv(path_or_buf = DATAPATH + '/preprocessed.csv', index = False)\n",
    "\n",
    "#start splitting into training set, validation set and test set\n",
    "features = dataset[['image_name', 'width', 'height', 'xmin', 'ymin', 'xmax', 'ymax']]\n",
    "labels = dataset['label']\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 4471)\n",
    "train_features, valid_features, train_labels, valid_labels = train_test_split(train_features, train_labels, test_size = 815, random_state = 4471)\n",
    "\n",
    "train_features.insert(7, 'label', train_labels)\n",
    "test_features.insert(7, 'label', test_labels)\n",
    "valid_features.insert(7, 'label', valid_labels)\n",
    "\n",
    "train = train_features\n",
    "test = test_features\n",
    "valid = valid_features\n",
    "\n",
    "print(train)\n",
    "print()\n",
    "print(test)\n",
    "print()\n",
    "print(valid)\n",
    "print()\n",
    "\n",
    "train.to_csv(path_or_buf = DATAPATH + '/train.csv', index = False)\n",
    "test.to_csv(path_or_buf = DATAPATH + '/test.csv', index = False)\n",
    "valid.to_csv(path_or_buf = DATAPATH + '/valid.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset class\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform = None):\n",
    "        self.df = pd.read_csv(csv_file)      \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.df['image_name'][idx]\n",
    "        label = self.df['label'][idx]\n",
    "        \n",
    "        image = Image.open(IMAGEPATH + '/' + image)\n",
    "        image = image.convert('RGB') #3 channels\n",
    "\n",
    "        (left, upper, right, lower) = (int(self.df['xmin'][idx]), int(self.df['ymin'][idx]), int(self.df['xmax'][idx]), int(self.df['ymax'][idx])) #coordinate of bounding box\n",
    "        image = image.crop((left, upper, right, lower)) #the cropped image, which is the face\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset and dataloader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize([32, 32])]) # resize to 32 x 32\n",
    "\n",
    "trainset = ImageDataset(DATAPATH + '/train.csv', transform)\n",
    "validset = ImageDataset(DATAPATH + '/valid.csv', transform)\n",
    "testset = ImageDataset(DATAPATH + '/test.csv', transform)\n",
    "\n",
    "bs = 64\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size = bs, shuffle = True)\n",
    "valid_loader = DataLoader(validset, batch_size = bs, shuffle = False)\n",
    "test_loader = DataLoader(testset, batch_size = bs, shuffle = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f03e8dbffa71d97b3bf9ac3bc744e638a5a424bac07c0ebb75a70fccc67a607"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('comp4211': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
